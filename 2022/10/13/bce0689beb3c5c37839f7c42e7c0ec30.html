<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>sidekiqçš„api</title>
<meta name="generator" content="Jekyll v3.8.6" />
<meta property="og:title" content="sidekiqçš„api" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="beegoæ˜¯ä¸€ä¸ªMVCæ¡†æ¶ï¼Œä¸railsç±»ä¼¼ï¼Œå…¶é¡¹ç›®ä»£ç æœ‰ä¸€å¥—æ¨èçš„ç›®å½•ç»“æ„ï¼Œç”¨æˆ·åªéœ€å¾€é‡Œé¢å¡«å……ä»£ç å³å¯å®ç°è·¯ç”±ã€è¿‡æ»¤ã€ORMç­‰åŠŸèƒ½â€¦" />
<meta property="og:description" content="beegoæ˜¯ä¸€ä¸ªMVCæ¡†æ¶ï¼Œä¸railsç±»ä¼¼ï¼Œå…¶é¡¹ç›®ä»£ç æœ‰ä¸€å¥—æ¨èçš„ç›®å½•ç»“æ„ï¼Œç”¨æˆ·åªéœ€å¾€é‡Œé¢å¡«å……ä»£ç å³å¯å®ç°è·¯ç”±ã€è¿‡æ»¤ã€ORMç­‰åŠŸèƒ½â€¦" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-13T00:00:00+00:00" />
<script type="application/ld+json">
{"description":"beegoæ˜¯ä¸€ä¸ªMVCæ¡†æ¶ï¼Œä¸railsç±»ä¼¼ï¼Œå…¶é¡¹ç›®ä»£ç æœ‰ä¸€å¥—æ¨èçš„ç›®å½•ç»“æ„ï¼Œç”¨æˆ·åªéœ€å¾€é‡Œé¢å¡«å……ä»£ç å³å¯å®ç°è·¯ç”±ã€è¿‡æ»¤ã€ORMç­‰åŠŸèƒ½â€¦","@type":"BlogPosting","headline":"sidekiqçš„api","dateModified":"2022-10-13T00:00:00+00:00","url":"/2021/07/01/d4719e2ec0e7f6e099b645822bb66fd8.html","datePublished":"2022-10-13T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2021/07/01/d4719e2ec0e7f6e099b645822bb66fd8.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">some<strong>think</strong></a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/tags.html">æ ‡ç­¾</a><a class="page-link" href="/statistic.html">ç»Ÿè®¡</a><a class="page-link" href="/about.html">å…³äº</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">sidekiqçš„api</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2022-10-13T00:00:00+00:00" itemprop="datePublished">Oct 13, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div>åœ¨lib/sidekiq/api.rbä¸­ï¼Œä½¿ç”¨æ—¶å¯èƒ½éœ€è¦å…ˆ<code>require &#39;sidekiq/api&#39;</code></div><div><br /></div><div>å¯å‚è€ƒ <a href="https://shashwat-creator.medium.com/all-you-need-to-know-about-sidekiq-a4b770a71f8f">All you need to know about Sidekiq | by Shashwat Srivastava | Medium</a></div><div><br /></div><div><span style='font-weight: bold;'>Stats æ‰€æœ‰å³æ—¶å»¶æ—¶é‡è¯•é˜Ÿåˆ—é•¿åº¦å’Œæ‰§è¡Œç»Ÿè®¡</span></div><div><br /></div><div>ä¾‹å¦‚</div><div><br /></div><pre><code># æ‰€æœ‰å³æ—¶é˜Ÿåˆ—çš„åç§°å’Œé•¿åº¦
Sidekiq::Stats.new.queues

# å…¶ä»–
Sidekiq::Stats.new.instance_variable_get(:@stats)
</code></pre><div><br /></div><div>æºç </div><div><br /></div><pre><code>class Stats
  def initialize
    fetch_stats_fast!
  end

  # è¿”å›æ¯ä¸ªé˜Ÿåˆ—çš„å½“å‰é•¿åº¦ï¼Œæ ¼å¼ {queue1: 213, queue2: 698 ...}
  def queues
    Sidekiq::Stats::Queues.new.lengths
  end

  def fetch_stats_fast!
    pipe1_res = Sidekiq.redis { |conn|
      conn.pipelined do |pipeline|
        # æ€»æ‰§è¡Œæ¬¡æ•°
        pipeline.get("stat:processed")
        # æ€»å¤±è´¥æ¬¡æ•°
        pipeline.get("stat:failed")
        # æœªåˆ°æ—¶å€™çš„å®šæ—¶ä»»åŠ¡æ•°é‡
        pipeline.zcard("schedule")
        # ç­‰å¾…é‡è¯•çš„ä»»åŠ¡æ•°é‡
        pipeline.zcard("retry")
        # deadé›†åˆå¤§å°
        pipeline.zcard("dead")
        # sidekiqè¿›ç¨‹æ•°
        pipeline.scard("processes")
        # defaulté˜Ÿåˆ—çš„å»¶è¿Ÿ
        pipeline.lrange("queue:default", -1, -1)
      end
    }

    default_queue_latency = if (entry = pipe1_res[6].first)
      job = begin
        Sidekiq.load_json(entry)
      rescue
        {}
      end
      now = Time.now.to_f
      thence = job["enqueued_at"] || now
      now - thence
    else
      0
    end

    @stats = {
      processed: pipe1_res[0].to_i,
      failed: pipe1_res[1].to_i,
      scheduled_size: pipe1_res[2],
      retry_size: pipe1_res[3],
      dead_size: pipe1_res[4],
      processes_size: pipe1_res[5],

      default_queue_latency: default_queue_latency
    }
  end

  # O(number of processes + number of queues) redis calls
  # @api private
  def fetch_stats_slow!
    processes = Sidekiq.redis { |conn|
      conn.sscan_each("processes").to_a
    }

    queues = Sidekiq.redis { |conn|
      conn.sscan_each("queues").to_a
    }

    pipe2_res = Sidekiq.redis { |conn|
      conn.pipelined do |pipeline|
        # æ¯ä¸ªè¿›ç¨‹æ‰§è¡Œä¸­çš„ä»»åŠ¡æ•°
        processes.each { |key| pipeline.hget(key, "busy") }
        # æ¯ä¸ªé˜Ÿåˆ—çš„é•¿åº¦
        queues.each { |queue| pipeline.llen("queue:#{queue}") }
      end
    }

    s = processes.size
    workers_size = pipe2_res[0...s].sum(&:to_i)
    enqueued = pipe2_res[s..-1].sum(&:to_i)

    # æ‰€æœ‰è¿›ç¨‹é‡Œæ‰§è¡Œä¸­çš„ä»»åŠ¡æ•°
    @stats[:workers_size] = workers_size
    # å°±ç»ªä»»åŠ¡æ€»æ•°
    @stats[:enqueued] = enqueued
    @stats
  end

  # å°†stat:processedã€stat:failedé‡ç½®ä¸ºé›¶
  def reset(*stats)
    all = %w[failed processed]
    stats = stats.empty? ? all : all & stats.flatten.compact.map(&:to_s)

    mset_args = []
    stats.each do |stat|
      mset_args << "stat:#{stat}"
      mset_args << 0
    end
    Sidekiq.redis do |conn|
      conn.mset(*mset_args)
    end
  end

  class Queues
    # è¿”å›æ¯ä¸ªé˜Ÿåˆ—çš„å½“å‰é•¿åº¦ï¼Œæ ¼å¼ {queue1: 213, queue2: 698 ...}
    def lengths
      Sidekiq.redis do |conn|
        queues = conn.sscan_each("queues").to_a

        lengths = conn.pipelined { |pipeline|
          queues.each do |queue|
            pipeline.llen("queue:#{queue}")
          end
        }

        array_of_arrays = queues.zip(lengths).sort_by { |_, size| -size }
        array_of_arrays.to_h
      end
    end
  end

  # è·å–æ¯æ—¥æ‰§è¡Œæ•°å’Œå¤±è´¥æ•°
  class History
    # å–start_dateçš„days_previouså‰çš„è®°å½•
    def initialize(days_previous, start_date = nil)
      # we only store five years of data in Redis
      raise ArgumentError if days_previous < 1 || days_previous > (5 * 365)
      @days_previous = days_previous
      @start_date = start_date || Time.now.utc.to_date
    end

    def processed
      @processed ||= date_stat_hash("processed")
    end

    def failed
      @failed ||= date_stat_hash("failed")
    end

    private

    # ä½¿ç”¨mgetä¸€æ¬¡è·å–å¤šä¸ªstringå¯¹åº”çš„å€¼
    # stringæ˜¯å„ä¸ªæ—¥æœŸï¼šstat:processed:2022-10-03ã€stat:processed:2022-10-02 â€¦â€¦
    # æˆ–è€…stat:failed:2022-10-03
    def date_stat_hash(stat)
      stat_hash = {}
      dates = @start_date.downto(@start_date - @days_previous + 1).map { |date|
        date.strftime("%Y-%m-%d")
      }

      keys = dates.map { |datestr| "stat:#{stat}:#{datestr}" }

      begin
        Sidekiq.redis do |conn|
          conn.mget(keys).each_with_index do |value, idx|
            stat_hash[dates[idx]] = value ? value.to_i : 0
          end
        end
      rescue RedisConnection.adapter::CommandError
        # mget will trigger a CROSSSLOT error when run against a Cluster
        # TODO Someone want to add Cluster support?
      end

      stat_hash
    end
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>Queue éå†æˆ–æ¸…ç©ºæŸä¸ªå³æ—¶é˜Ÿåˆ—</span></div><div><br /></div><div>ä¾‹å¦‚</div><div><br /></div><pre><code># è·å–æŸä¸ªé˜Ÿåˆ—
Sidekiq::Queue.new('user_price_audit')

# éå†ï¼Œè¿”å›JobRecord
Sidekiq::Queue.new('user_price_audit').each{ ... }
</code></pre><div><br /></div><div>æºç </div><div><br /></div><pre><code>class Queue
  include Enumerable

  # ä½¿ç”¨sscanè¿­ä»£queuesè¿™ä¸ªset
  # å¹¶åŒ…è£…æˆQueueè¿”å›
  def self.all
    Sidekiq.redis { |c| c.sscan_each("queues").to_a }.sort.map { |q| Sidekiq::Queue.new(q) }
  end

  attr_reader :name

  # åˆ›å»ºä¸€ä¸ªQueueå¯¹è±¡ï¼Œå¯¹åº”redisä¸­æ˜¯queue:xxx
  def initialize(name = "default")
    @name = name.to_s
    @rname = "queue:#{name}"
  end

  # ä½¿ç”¨llenæ£€æŸ¥è¿™ä¸ªé˜Ÿåˆ—çš„é•¿åº¦
  def size
    Sidekiq.redis { |con| con.llen(@rname) }
  end

  # ä½¿ç”¨lrangeå–é˜Ÿåˆ—ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆå› ä¸ºå…¥é˜Ÿæ˜¯lpushï¼Œæ‰€ä»¥å–æœ€å³ï¼‰
  # ä»¥Time.nowå‡å…¶enqueued_atå¾—å»¶è¿Ÿ
  def latency
    entry = Sidekiq.redis { |conn|
      conn.lrange(@rname, -1, -1)
    }.first
    return 0 unless entry
    job = Sidekiq.load_json(entry)
    now = Time.now.to_f
    thence = job["enqueued_at"] || now
    now - thence
  end

  # ä»¥50ä¸ªå…ƒç´ ä¸€é¡µçš„æ–¹å¼ï¼Œç”¨lrangeä»å·¦å¾€å³è¯»å–é˜Ÿåˆ—
  # ä½†å› å…¶å®ƒçº¿ç¨‹ä¼šæœ‰å…¥é˜Ÿå‡ºé˜Ÿæ“ä½œï¼Œæ‰€ä»¥ä¸ä¸€å®šè¿ç»­ï¼Œå®ƒè®¡ç®—deleted_sizeå¯èƒ½ä¹Ÿæ²¡ç”¨
  def each
    initial_size = size
    deleted_size = 0
    page = 0
    page_size = 50

    loop do
      range_start = page * page_size - deleted_size
      range_end = range_start + page_size - 1
      entries = Sidekiq.redis { |conn|
        conn.lrange @rname, range_start, range_end
      }
      break if entries.empty?
      page += 1
      entries.each do |entry|
        yield JobRecord.new(entry, @name)
      end
      deleted_size = initial_size - size
    end
  end

  # ä½¿ç”¨Enumerableæä¾›çš„detect->eachä¸€ä¸ªä¸ªåŒ¹é…jidï¼Œæ•ˆç‡ä½
  def find_job(jid)
    detect { |j| j.jid == jid }
  end

  # ä½¿ç”¨unlinkéé˜»å¡åœ°åˆ é™¤æœ¬é˜Ÿåˆ—ï¼ˆè€Œdelæ˜¯é˜»å¡çš„ï¼‰
  # å¹¶ä¸”ä»queuesè¿™ä¸ªsetä¸­æå‡ºå…¶åå­—
  def clear
    Sidekiq.redis do |conn|
      conn.multi do |transaction|
        transaction.unlink(@rname)
        transaction.srem("queues", [name])
      end
    end
    true
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>JobRecord ä»»åŠ¡å¯¹è±¡</span></div><div><br /></div><pre><code>class JobRecord
  attr_reader :value # redisä¸­åŸå§‹çš„jsonå­—ç¬¦ä¸²
  attr_reader :item # jsonè§£ææˆhash
  attr_reader :queue

  def initialize(item, queue_name = nil)
    @args = nil
    @value = item
    @item = item.is_a?(Hash) ? item : parse(item)
    @queue = queue_name || @item["queue"]
  end

  # å½“å‰æ—¶é—´ä¸å…¥é˜Ÿæ—¶é—´çš„å·®å€¼
  def latency
    now = Time.now.to_f
    now - (@item["enqueued_at"] || @item["created_at"] || now)
  end

  # ä»Queueå–åˆ°ä¸€ä¸ªJobRecordåï¼Œå¯ä»¥è°ƒç”¨æ­¤æ–¹æ³•æ–¹ä¾¿åœ°åˆ é™¤å®ƒ
  def delete
    count = Sidekiq.redis { |conn|
      conn.lrem("queue:#{@queue}", 1, @value)
    }
    count != 0
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>SortedSet</span></div><div><br /></div><div>å°±ç»™<code>JobSet</code>ç»§æ‰¿è€Œå·²</div><div><br /></div><pre><code>class SortedSet
  include Enumerable

  attr_reader :name

  def initialize(name)
    @name = name
    @_size = size
  end

  # è¿”å›sorted setçš„å¤§å°
  def size
    Sidekiq.redis { |c| c.zcard(name) }
  end

  # éå†sorted setä¸­çš„å…ƒç´ ï¼Œå¹¶åŒ…è£…æˆSortedEntryè¿”å›
  def scan(match, count = 100)
    return to_enum(:scan, match, count) unless block_given?

    match = "*#{match}*" unless match.include?("*")
    Sidekiq.redis do |conn|
      conn.zscan_each(name, match: match, count: count) do |entry, score|
        yield SortedEntry.new(self, score, entry)
      end
    end
  end

  # éé˜»å¡åœ°ç§»é™¤è¿™ä¸ªsorted set
  def clear
    Sidekiq.redis do |conn|
      conn.unlink(name)
    end
    true
  end
  alias_method :ğŸ’£, :clear
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>JobSet &lt; SortedSet</span></div><div><br /></div><div>â€œå­˜æ”¾ä»»åŠ¡çš„sorted setâ€çš„åŸºç±»ï¼Œç”¨äº<code>schedule</code>ã€<code>retry</code>ã€<code>dead</code></div><div><br /></div><div>æä¾›<code>each</code>æ–¹æ³•ä»¥æ»¡è¶³<code>Enumerable</code></div><div><br /></div><pre><code>class JobSet < SortedSet
  def each
    initial_size = @_size
    offset_size = 0
    page = -1
    page_size = 50

    loop do
      range_start = page * page_size + offset_size
      range_end = range_start + page_size - 1
      elements = Sidekiq.redis { |conn|
        conn.zrange name, range_start, range_end, withscores: true
      }
      break if elements.empty?
      page -= 1
      elements.reverse_each do |element, score|
        yield SortedEntry.new(self, score, element)
      end
      offset_size = initial_size - @_size
    end
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>ScheduledSet &lt; JobSet &lt; SortedSet å»¶æ—¶é˜Ÿåˆ—</span></div><div><br /></div><div>ä¾‹å¦‚</div><div><br /></div><pre><code># æ€»æ•°
Sidekiq::ScheduledSet.new.count

# éå†ï¼Œè¿”å›SortedEntry < JobRecord
Sidekiq::ScheduledSet.new.each{...}

# å–æŸä¸ªå»¶æ—¶ä»»åŠ¡çœ‹çœ‹
Sidekiq::ScheduledSet.new.first #.item['args']

# åˆ é™¤æŸç§å»¶æ—¶job
Sidekiq::ScheduledSet.new.each{|j| j.kill if j.item.dig('args', 0, 'job_class') == 'SuperPricesAuditor'}
</code></pre><div><br /></div><div><span style='font-weight: bold;'>RetrySet &lt; JobSet &lt; SortedSet é‡è¯•é˜Ÿåˆ—</span></div><div><br /></div><div>ä¾‹å¦‚</div><div><br /></div><pre><code># æ€»æ•°
Sidekiq::RetrySet.new.count

# æ‰¹é‡æ“ä½œ
Sidekiq::RetrySet.new.retry_all
Sidekiq::RetrySet.new.kill_all

# éå†ï¼Œè¿”å›SortedEntry < JobRecord
Sidekiq::RetrySet.new.each{...}

# å–æŸä¸ªé‡è¯•ä»»åŠ¡çœ‹çœ‹
Sidekiq::RetrySet.new.first #.item['args']

# åˆ é™¤æŸç§é‡è¯•job
Sidekiq::RetrySet.new.each{|j| j.kill if j.item.dig('args', 0, 'job_class') == 'SuperPricesAuditor'}
</code></pre><div><br /></div><div>æºç </div><div><br /></div><pre><code>class RetrySet < JobSet
  def initialize
    super "retry"
  end

  # Enqueues all jobs pending within the retry set.
  def retry_all
    each(&:retry) while size > 0
  end

  # Kills all jobs pending within the retry set.
  def kill_all
    each(&:kill) while size > 0
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>WorkSet</span></div><div><br /></div><div>æŸ¥çœ‹è¿è¡Œä¸­çš„ä»»åŠ¡</div><div><br /></div><pre><code>class WorkSet
  include Enumerable

  # ä»processesè¿™ä¸ªsetä¸­å¾—æ‰€æœ‰sidekiqå®ä¾‹idï¼šhost+pid+rand
  # å†ä»æ¯ä¸ª"#{host+pid+rand}:work"çš„hashä¸­è·å–keyï¼ˆçº¿ç¨‹idï¼‰å’Œvalueï¼ˆä»»åŠ¡ï¼‰
  def each(&block)
    results = []
    Sidekiq.redis do |conn|
      procs = conn.sscan_each("processes").to_a
      procs.sort.each do |key|
        valid, workers = conn.pipelined { |pipeline|
          pipeline.exists?(key)
          pipeline.hgetall("#{key}:work")
        }
        next unless valid
        workers.each_pair do |tid, json|
          hsh = Sidekiq.load_json(json)
          p = hsh["payload"]
          # avoid breaking API, this is a side effect of the JSON optimization in #4316
          hsh["payload"] = Sidekiq.load_json(p) if p.is_a?(String)
          results << [key, tid, hsh]
        end
      end
    end

    results.sort_by { |(_, _, hsh)| hsh["run_at"] }.each(&block)
  end

  # å–æ¯ä¸ª"#{host+pid+rand}"çš„hashé‡Œçš„busyé¡¹ï¼ŒåŠ æ€»
  # "#{host+pid+rand}"æ˜¯heartbeatå®šæœŸå†™å…¥çš„ï¼Œä¸å¤ªå®æ—¶ï¼Œä½†å†…å®¹å°‘ï¼Œæ¯”ä¸Šé¢çš„å¿«
  def size
    Sidekiq.redis do |conn|
      procs = conn.sscan_each("processes").to_a
      if procs.empty?
        0
      else
        conn.pipelined { |pipeline|
          procs.each do |key|
            pipeline.hget(key, "busy")
          end
        }.sum(&:to_i)
      end
    end
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>Paginator</span></div><div><br /></div><div>æ ¹æ®ç¬¬ä¸€ä¸ªå‚æ•°keyï¼ˆå¯èƒ½æ˜¯<code>&quot;queue:#{@name}&quot;</code>ã€<code>&quot;dead&quot;</code>ã€<code>&quot;retry&quot;</code>ã€<code>&quot;schedule&quot;</code>ï¼‰æ‰€æŒ‡çš„valueçš„ç±»å‹ï¼ˆå¯èƒ½æ˜¯zsetã€listï¼‰ï¼Œé‡‡ç”¨ä¸åŒçš„redisæŒ‡ä»¤æ¥åˆ‡åˆ†é›†åˆ</div><div><br /></div><pre><code>module Sidekiq
  module Paginator
    def page(key, pageidx = 1, page_size = 25, opts = nil)
      current_page = pageidx.to_i < 1 ? 1 : pageidx.to_i
      pageidx = current_page - 1
      total_size = 0
      items = []
      starting = pageidx * page_size
      ending = starting + page_size - 1

      Sidekiq.redis do |conn|
        type = conn.type(key)
        rev = opts && opts[:reverse]

        case type
        when "zset"
          total_size, items = conn.multi { |transaction|
            transaction.zcard(key)
            if rev
              transaction.zrevrange(key, starting, ending, withscores: true)
            else
              transaction.zrange(key, starting, ending, withscores: true)
            end
          }
          [current_page, total_size, items]
        when "list"
          total_size, items = conn.multi { |transaction|
            transaction.llen(key)
            if rev
              transaction.lrange(key, -ending - 1, -starting - 1)
            else
              transaction.lrange(key, starting, ending)
            end
          }
          items.reverse! if rev
          [current_page, total_size, items]
        when "none"
          [1, 0, []]
        else
          raise "can't page a #{type}"
        end
      end
    end
  end
end
</code></pre><div><br /></div><div>ä»¥ä¸‹æ˜¯ä¸€ä¸ªå–scheduleä»»åŠ¡çš„ä¾‹å­ï¼š</div><div><br /></div><pre><code>PAGINATOR = Class.new.tap{ |k| k.include ::Sidekiq::Paginator }.new

current_page, total_size, retries = PAGINATOR.page("schedule", 1, 1000)

retries.each do |msg, score|
  se = Sidekiq::SortedEntry.new(nil, score, msg)
  if se.item.dig('args', 0, 'job_class') == 'Price::DeleteSystemJob' &&
    se.item.dig('args', 0, 'arguments', 0, 'customer_firm_id') == 27735
    # ...
  end
end
</code></pre><div><br /></div><div><span style='font-weight: bold;'>ProcessSet</span></div><div><br /></div><div>æ‰€æœ‰è¿›ç¨‹çš„æ¦‚è§ˆï¼šæ€»è¿›ç¨‹æ•°ï¼Œæ€»çº¿ç¨‹å¹¶å‘æ•°ï¼Œæ€»å†…å­˜å ç”¨ã€‚å¯è¿­ä»£æ¯ä¸ªè¿›ç¨‹</div><div><br /></div><pre><code>class ProcessSet
  include Enumerable

  # åŒ…è£…æˆProcesså¯¹è±¡ï¼Œè¿­ä»£
  def each
    result = Sidekiq.redis { |conn|
      procs = conn.sscan_each("processes").to_a.sort
      conn.pipelined do |pipeline|
        procs.each do |key|
          pipeline.hmget(key, "info", "busy", "beat", "quiet", "rss", "rtt_us")
        end
      end
    }

    result.each do |info, busy, at_s, quiet, rss, rtt|
      next if info.nil? 949
      hash = Sidekiq.load_json(info)
      yield Process.new(hash.merge("busy" => busy.to_i,
        "beat" => at_s.to_f,
        "quiet" => quiet,
        "rss" => rss.to_i,
        "rtt_us" => rtt.to_i))
    end
  end

  # è¿›ç¨‹æ•°
  def size
    Sidekiq.redis { |conn| conn.scard("processes") }
  end

  # å–æ¯ä¸ªsidekiqè¿›ç¨‹é…ç½®çš„çº¿ç¨‹æ•°ï¼ŒåŠ æ€»
  def total_concurrency
    sum { |x| x["concurrency"].to_i }
  end

  # å¿ƒè·³å†™å…¥çš„è¿›ç¨‹å†…å­˜å ç”¨é‡ï¼ŒåŠ æ€»
  def total_rss_in_kb
    sum { |x| x["rss"].to_i }
  end
  alias_method :total_rss, :total_rss_in_kb
end
</code></pre><div><br /></div>
  </div><a class="u-url" href="/" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading"></h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name"></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
